# directive: Process to execute
# - 0: train network
# - 1: run evaluation
# - 2: train+eval (effectively couples 0 and 1)
# - 3: specific multi-step pipeline
# - 4: load results/copy to local for viewing
# - 5: MEEP simulations
# - 6: data preprocessing and formatting for model
# - 7: mode encoding
# - 8: mode reconstruction
# deployment: Deployment mode
# - 0: local
# - 1: kubernetes

directive: 2
deployment: 1


#--------------------------------
#       General Params
#--------------------------------

# General Parameters
# - seed: random seed - often 1337


seed: 1337

#--------------------------------
#       Network Params
#--------------------------------

model:
    # - arch: Network Architecture
    # *** Learning a mapping from design parameters to DFT fields ***
        # - 0: Forward - Dual MLPs - separate MLPs for real and imaginary
        # - 1: Forward - CVNN - Complex-valued MLP
        # - 2: Inverse Design - using CVNN. inverse_strategy (below) specifies ID method
    # *** Learning wavefront propagation ***
        # - 3: LSTM
        # - 4: ConvLSTM
        # - 5: AE-LSTM - LSTM with linear autoencoder
        # - 6: AE-ConvLSTM - ConvLSTM with convolutional autoencoder
        # - 7: mode-LSTM - LSTM operating on a deterministic dim reduction of the fields
            # - SVD, random projection, gauss, fourier
        # - 8: diffusion - img2video diffuser model
        # - 9: transformer - simple attention-based approach
    # *** Learning a reconstrutible latent representation of the fields ***
        # - 10: Autoencoder - Used in conjunction with arch 4, 5
    # *** Full-wave surrogate model ***
        # - 11: MLP-LSTM - MLP followed by LSTM
    # - model_id: model identifier / name

    arch: 3
    model_id: 'kloss-v1'

    # General Model Parameters

    optimizer: 'ADAM'
    learning_rate: 1.e-4
    lr_scheduler: 'CosineAnnealingLR'
    load_checkpoint: False
    objective_function: 'kspace'

    # multi-criteria loss
    # - currently used dynamically based on the choice of 'objective_function' above.
    # - --- if 'objective_function' is 'ssim', alpha controls MSE contribution, beta controls SSIM.
    # - --- if it is 'kspace', alpha: kMag, beta: kPhase, gamma: kRadial, and delta: kAngular.
    mcl_params:
        alpha: 1
        beta: 0.8
        gamma: 1
        delta: 1

    # ssim specs
    ssim:
        window_size: 11

    # MLP Parameters
    # - ***separate MLPs for real and imaginary parts, or a single CVNN***
    # - layers: Hidden layer neuron counts, len(layers) = number of hidden layers
    # - activation: Activation function for hidden layers
    # - forward_strategy: 0: full, 1: patch-wise 2: distributed subset 3: NETWORK 2 field -> field
    # - inverse_strategy: 0: naive, 1: tandem, ETC
    # - num_design_conf: number of design configurations (usually 3x3: 9)
    # - near_field_dim: dimensionality of xdim or ydim of the near field response map
    # - --- NOTE: 166 for radii, 56 for refractive index (for the data we currently have at least)
    # - patch_size: patch height/width for patch wise or distributed subset

    mlp_real:
        layers: [32, 64, 256]
        activation: 'relu'

    mlp_imag:
        layers: [32, 64, 256]
        activation: 'relu'

    cvnn:
        layers: [32, 64, 256]
        activation: 'complexrelu'

    dropout: 0.0
    forward_strategy: 0
    inverse_strategy: 0
    patch_size: 3
    num_design_conf: 9
    near_field_dim: 166
    interpolate_fields: False
    forward_ckpt: '/develop/results/meep_meep/refractive_idx/cvnn/model_forward-BASELINE/model.ckpt'

    # LSTM Parameters
    # - num_layers: number of lstm layers (i.e., stacked networks)
    # - i_dims: number of input dimensions for lstm
    # - h_dims: number of hidden dimensions for lstm

    lstm:
        num_layers: 1
        i_dims: 55112 # this is (r/i * 166 * 166)
        h_dims: 256

    # Mode-LSTM Parameters - LSTM but data has already been encoded
    # - spatial: spatial size of the input
    # - w0: beam waist parameter (laguerre-gaussian)
    # - p_max: radial index max (laguerre-gaussian)
    # - l_max: azimuthal index max (laguerre-gaussian)
    # - method: encoding types ('svd' or 'random' or 'gauss' or 'fourier')

    modelstm:
        num_layers: 1
        h_dims: 64
        k: 15
        spatial: 166
        w0: 1.0
        p_max: 39
        l_max: 20
        seed: 1337
        method: 'svd'


    # ConvLSTM Parameters
    # - in_channels: number of input channels for conv
    # - kernel_size: size of the conv kernel
    # - padding: padding for the conv layer
    # - use_ae: utilize autoencoder
    # - pretrained_ae: use pretrained autoencoder
    # - latent_dim: latent dimension for autoencoder
    # - encoder_channels: encoder channel progression
    # - decoder_channels: decoder channel progression
    # - use_smoothing: whether to use smoothing
    convlstm:
        num_layers: 1
        in_channels: 2
        out_channels: 64
        kernel_size: 5
        padding: 2
        spatial: 166
        use_smoothing: False

    # Autoencoder Parameters
    # - encoder_channels: encoder channel progression (number of channels at each downsampling step)
    # - decoder_channels: decoder channel progression (number of channels at each upsampling step)
    # - latent_dim: size of the latent space (e.g., 14 for 14x14, 28 for 28x28)
    # - spatial: input/output spatial size (e.g., 56 for 56x56)
    # - method: layer types ('conv' only supported currently)
    # - pretrained: use pretrained autoencoder
    # - freeze_weights: whether to freeze weights
    # - use_decoder: whether to use decoder (for encoder-only mode)

    autoencoder:
        # Current implementation (56x56 -> 14x14)
        encoder_channels: [16, 32]  # Channels at each downsampling step
        decoder_channels: [32, 16]  # Channels at each upsampling step
        latent_dim: 14  # Results in 14x14 latent space
        spatial: 56    # Input/output size
        method: 'conv'
        pretrained: True
        freeze_weights: False
        use_decoder: True

        # Example for 56x56 -> 28x28
        # encoder_channels: [16]  # Single downsampling step
        # decoder_channels: [16]  # Single upsampling step
        # latent_dim: 28         # Results in 28x28 latent space
        # spatial: 56           # Input/output size

        # Example for 56x56 -> 7x7
        # encoder_channels: [16, 32, 64]  # Three downsampling steps
        # decoder_channels: [64, 32, 16]  # Three upsampling steps
        # latent_dim: 7          # Results in 7x7 latent space
        # spatial: 56           # Input/output size

    # Diffusion Parameters
    # - num_generated_frames: number of frames to generate
    # - prompt: prompt for diffusion model

    diffusion:
        num_generated_frames: 14
        prompt: ''
        use_half_precision: True

    # Transformer Parameters
    # - patch_size: size of patches to split input into
    # - embed_dim: dimensionity in embedding space
    # - depth: total layers (e.g., 6 encoder, 6 decoder)
    # - num_heads: attention heads
    # - mlp_ratio:

    transformer:
        patch_size: 11
        embed_dim: 384
        depth: 4
        num_heads: 8
        mlp_ratio: 4.0
        use_diff_loss: False
        lambda_diff: 0.1

    # General Time Series Parameters
    # - seq_len: number of time steps
    # - io_mode: 'one_to_many' or 'many_to_many'
    # - spacing_mode: 'sequential' or 'distributed'
    # - autoreg: autoregressive mode or teacher forcing - M2M only

    seq_len: 15
    io_mode: 'one_to_many'
    spacing_mode: 'sequential'
    autoreg: True

#--------------------------------
#       Training Params
#--------------------------------
trainer:
    batch_size: 8
    num_epochs: 50 # maximum

    accelerator: 'gpu' 
    gpu_config: [True, [0]]
    matmul_precision: 'medium'
    valid_rate: 1
    load_checkpoint:
        mlp: True
        lstm: True

    # pick up where it left off
    resume: False

    # - cross_validation: True/False - whether to perform cross-validation
    # ---> if False, then a 5-fold 80/20 split is used
    cross_validation: False

    # early stopping settings
    patience: 15
    min_delta: 0.0001

    # plot settings
    plot_ssim_corr: True

#--------------------------------
#       All paths
#--------------------------------
paths:
    root: '/develop/'
    data: 'data/'
    train: 'train/'
    valid: 'valid/'
    results: 'results/meep_meep/'
    volumes: 'nfe-data/volumes'
    library: 'code/near_field_emulator/utils/neighbors_library_allrandom.pkl'
    library_refidx: 'code/near_field_emulator/utils/library_refidx.pkl'
    #pretrained_ae: 'autoencoder/model_ae-v1/' # for AE-LSTM models
    pretrained_ae: 'refractive_idx/autoencoder/model_refidx-v2/'
    pretrained_mlp: 'surrogate/model_BASELINE/mlp/'
    pretrained_lstm: 'mlp/model_net2B-BASELINE/'
    checkpoint: 'radii/transformer/model_baseline-mcl/'
    mlp_results: 'mlp/model_BASELINE/'

#--------------------------------
#       Physical Params
#--------------------------------
physics:
    #Metasurface simulation
    Nx_metaAtom: 3
    Ny_metaAtom: 3
    Lx_metaAtom: 680.e-9
    Ly_metaAtom: 680.e-9

    n_fusedSilica: 1.44
    n_PDMS: 1.4
    n_amorphousSilica: 3.48

    h_pillar: 102.e-9
    thickness_pml: 780.e-9
    thickness_fusedSilica: 780.e-9
    thickness_PDMS: 1560.e-9

    #General
    wavelength: 1550.e-9

    #Fourier propagation
    distance: 10.e-6
    Nxp: 176
    Nyp: 176
    Lxp: 2.04e-6
    Lyp: 2.04e-6
    adaptive: True

    #experiment type - what was varied (pillar radii, height, refractive idx, etc.)
    # for preprocessing. current support for "radius" and "refidx"
    material_parameter: "radius"

#--------------------------------
#       Datamodule Params
#--------------------------------
data:
    # - n_cpus: number of cpus
    # - n_folds: number of folds for cross val
    # - buffer: True/False - whether to use buffer dataset or old U-Net data (no buffer)
    # - wv_dict: dictionary of the possible wavelengths, numbered ascending
    # - wv_preprocess, wv_train and wv_eval refer to indices of wavelengths in wv_dict
    # ---> they control which wavelengths are used for their respective tasks
    # ---> wv_preprocess has to be a single value, wv_train and wv_eval can be multiple values
    # - normalize: True/False - whether to normalize the data before training (UNIMPLEMENTED)
    # - standardize: True/False - same as above but standardization

    n_cpus: 5
    n_folds: 5
    buffer: True
    wv_dict: {'1': 1.06, '2': 1.3, '3': 1.55, '4': 1.65, '5': 2.881}
    wv_preprocess: '3'
    wv_train: '3'
    wv_eval: '3'
    normalize: True
    standardize: False

#--------------------------------
#       Kube Params
#--------------------------------
kube:
    namespace : gpn-mizzou-muem
    image : docker.io/kovaleskilab/ml_basic:v4-kube
    job_files : /develop/code/near_field_emulator/kube/jobs  # this is a local directory
    pvc_volumes : dft-volumes-refidx # use `kubectl get pvc` to see list of pvcs
    pvc_preprocessed : refidx-data
    pvc_results : training-results

    data_job:
        num_cpus : 32
        num_parallel_ops : 2
        num_mem_lim : 200Gi 
        num_mem_req : 200Gi
        kill_tag : data-job

        paths:
            # local / repo path where meta-atom radii are stored

            # interactive pod directories
            data:
                volumes: /develop/results  # points to folder containing reduced volumes in pvc called dft-volumes
                preprocessed_data: /develop/data/preprocessed_data # points to folder containing data after it has been preprocessed in pvc called preprocessed-data 
            timing: /develop/data/timing 

            # local path where template is located
            template: kube/templates/data_job.txt

    train_job :
        num_cpus : 24
        num_mem_lim : 250Gi
        num_mem_req : 250Gi
        num_gpus : 1
        kill_tags : [mlp,lstm,convlstm]
    
        paths :
            data :
                train : /develop/data/preprocessed_data/train
                valid : /develop/data/preprocessed_data/valid
            results :
                # interactive pod directories
                model_results : /develop/results
                model_checkpoints : /develop/results/checkpoints
                analysis : /develop/results/analysis
            logs : /develop/results/checkpoints/current_logs
            # local path where template is located
            template : kube/templates/train_job.txt

    load_results_job :
        num_mem_req : 64Gi
        num_mem_lim : 128Gi
        paths :
            template : templates/load_results_job.txt
            params: /develop/code/near_field_emulator/configs/params.yaml

    evaluation_job :
        paths:
            template : kube/templates/evaluation_job.txt

#--------------------------------
#       Pipeline Params
#--------------------------------

pipeline:
  - phase_name: "mlp"
    model_arch: "mlp"
    processor: "MLPProcessor"
  - phase_name: "mlp"
    model_arch: "mlp"
    processor: "MLPProcessor"
